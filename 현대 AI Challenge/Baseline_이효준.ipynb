{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/gdrive')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Csh1335uTrY0",
        "outputId": "7319fae8-e43b-4bea-a785-f7bd4abc6288"
      },
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mounted at /content/gdrive\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "id": "mt2U3SwUTX_e"
      },
      "outputs": [],
      "source": [
        "import pandas as pd\n",
        "import numpy as np\n",
        "\n",
        "from tqdm import tqdm\n",
        "\n",
        "from sklearn.metrics import mean_absolute_error\n",
        "from sklearn.preprocessing import LabelEncoder\n",
        "from sklearn.model_selection import KFold, GroupKFold\n",
        "\n",
        "import xgboost\n",
        "import lightgbm\n",
        "\n",
        "import tensorflow as tf\n",
        "\n",
        "import bisect"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "class CFG:\n",
        "  folds = 5\n",
        "\n",
        "  hidden_layers = 10\n",
        "  hidden_size = 24\n",
        "  activation = 'relu'\n",
        "\n",
        "  PATH = '/content/gdrive/MyDrive/Dacon/HD AI Challenge/datasets/'"
      ],
      "metadata": {
        "id": "38NFDcFEYuVz"
      },
      "execution_count": 2,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "train = pd.read_csv(CFG.PATH + 'train.csv')\n",
        "test = pd.read_csv(CFG.PATH + 'test.csv')\n",
        "sample_submission = pd.read_csv(CFG.PATH + 'sample_submission.csv')"
      ],
      "metadata": {
        "id": "A8r2RwnpT-7v"
      },
      "execution_count": 3,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#train = train.dropna(axis=0).reset_index(drop=True)\n",
        "#train = train.sort_values('ATA').reset_index(drop=True)"
      ],
      "metadata": {
        "id": "egPszurYZ74l"
      },
      "execution_count": 4,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "train['ATA'] = pd.to_datetime(train['ATA'])\n",
        "test['ATA'] = pd.to_datetime(test['ATA'])\n",
        "\n",
        "for df in [train, test]:\n",
        "  df['year'] = df['ATA'].dt.year\n",
        "  df['month'] = df['ATA'].dt.month\n",
        "  df['day'] = df['ATA'].dt.day\n",
        "  df['hour'] = df['ATA'].dt.hour\n",
        "  df['minute'] = df['ATA'].dt.minute\n",
        "  df['weekday'] = df['ATA'].dt.weekday\n",
        "\n",
        "#train.drop(columns='ATA', inplace=True)\n",
        "#test.drop(columns='ATA', inplace=True)"
      ],
      "metadata": {
        "id": "H54KvMSVWPrQ"
      },
      "execution_count": 5,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#train.fillna(train.mean(), inplace=True)\n",
        "#test.fillna(test.mean(), inplace=True)"
      ],
      "metadata": {
        "id": "sXWtcpNTJlgm"
      },
      "execution_count": 6,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "categorical_features = ['ARI_CO', 'ARI_PO', 'SHIP_TYPE_CATEGORY', 'ID', 'SHIPMANAGER', 'FLAG']\n",
        "encoders = {}\n",
        "\n",
        "for feature in tqdm(categorical_features):\n",
        "  le = LabelEncoder()\n",
        "  train[feature] = le.fit_transform(train[feature].astype(str))\n",
        "  le_classes_set = set(le.classes_)\n",
        "  test[feature] = test[feature].map(lambda s:'-1' if s not in le_classes_set else s)\n",
        "  le_classes = le.classes_.tolist()\n",
        "  bisect.insort_left(le_classes, '-1')\n",
        "  le.classes_ = np.array(le_classes)\n",
        "  test[feature] = le.transform(test[feature].astype(str))\n",
        "  encoders[feature] = le"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "AVwtN7LnFm5p",
        "outputId": "e08fb7ba-7e17-424d-ee26-33acefb12816"
      },
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 6/6 [00:04<00:00,  1.22it/s]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "train.drop(train[(train['DIST'] == 0) & (train['CI_HOUR'] != 0)].index, inplace=True)\n",
        "#train.drop(train[train['DIST'] == 0].index, inplace=True)\n",
        "train = train.reset_index(drop=True)"
      ],
      "metadata": {
        "id": "SMbSBi1eXfar"
      },
      "execution_count": 8,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "train.columns"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "oUOYIrjh7fza",
        "outputId": "6b23f878-35e9-42ab-c57d-93417e12fe11"
      },
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "Index(['SAMPLE_ID', 'ARI_CO', 'ARI_PO', 'SHIP_TYPE_CATEGORY', 'DIST', 'ATA',\n",
              "       'ID', 'BREADTH', 'BUILT', 'DEADWEIGHT', 'DEPTH', 'DRAUGHT', 'GT',\n",
              "       'LENGTH', 'SHIPMANAGER', 'FLAG', 'U_WIND', 'V_WIND', 'AIR_TEMPERATURE',\n",
              "       'BN', 'ATA_LT', 'DUBAI', 'BRENT', 'WTI', 'BDI_ADJ', 'PORT_SIZE',\n",
              "       'CI_HOUR', 'year', 'month', 'day', 'hour', 'minute', 'weekday'],\n",
              "      dtype='object')"
            ]
          },
          "metadata": {},
          "execution_count": 9
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "features = ['ARI_CO', 'ARI_PO', 'SHIP_TYPE_CATEGORY', 'DIST',\n",
        "            'BREADTH', 'DEADWEIGHT', 'DEPTH', 'DRAUGHT', 'GT',\n",
        "            'LENGTH', 'FLAG', 'WTI', 'BDI_ADJ', 'PORT_SIZE',\n",
        "            'year', 'month']   #ATA_LT\n",
        "\n",
        "target = 'CI_HOUR'"
      ],
      "metadata": {
        "id": "CwGnlL9cWgKA"
      },
      "execution_count": 15,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "extract = ['ARI_CO', 'ARI_PO', 'SHIP_TYPE_CATEGORY', 'DIST',\n",
        "           'BREADTH', 'DEADWEIGHT', 'DEPTH', 'DRAUGHT', 'GT',\n",
        "           'LENGTH', 'FLAG', 'ATA_LT', 'WTI', 'BDI_ADJ', 'PORT_SIZE',\n",
        "           'year', 'month', 'CI_HOUR']"
      ],
      "metadata": {
        "id": "7KqnDlM39QmJ"
      },
      "execution_count": 11,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "train = train[extract]\n",
        "train = train.dropna(axis=0).reset_index(drop=True)"
      ],
      "metadata": {
        "id": "7W21dKrS88MV"
      },
      "execution_count": 12,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "X_test = test[features]"
      ],
      "metadata": {
        "id": "7gvlHwST2942"
      },
      "execution_count": 13,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "kf = KFold(n_splits=CFG.folds, shuffle=True, random_state=42)\n",
        "#gkf = GroupKFold(n_splits=CFG.folds)\n",
        "xgb = xgboost.XGBRegressor(n_estimators=1000, max_depth=9, learning_rate=0.2)\n",
        "#gru = build_model()\n",
        "#mlp = build_model()\n",
        "lgbm = lightgbm.LGBMRegressor()\n",
        "\n",
        "mae_score = 0\n",
        "#test_predictions = []\n",
        "for fold, (train_idx, valid_idx) in enumerate(kf.split(train)):\n",
        "  X_train, y_train = train.loc[train_idx, features], train.loc[train_idx, target]\n",
        "  X_valid, y_valid = train.loc[valid_idx, features], train.loc[valid_idx, target]\n",
        "\n",
        "  xgb.fit(X_train, y_train)\n",
        "  lgbm.fit(X_train, y_train)\n",
        "  #xgb_pred = xgb.predict(X_valid)\n",
        "  #xgb_pred[X_valid['DIST'] == 0] = 0\n",
        "\n",
        "  #gru.fit(X_train, y_train, validation_data = (X_valid, y_valid), batch_size = 16, epochs = 1)\n",
        "  #gru_pred = gru.predict(X_valid)\n",
        "\n",
        "  pred = (lgbm.predict(X_valid) + xgb.predict(X_valid)) / 2\n",
        "  pred[X_valid['DIST'] == 0] = 0\n",
        "  pred = np.where(pred < 0, 0, pred)\n",
        "\n",
        "  print(f'Fold{fold} MAE: ', mean_absolute_error(y_valid, pred))\n",
        "\n",
        "  mae_score += mean_absolute_error(y_valid, pred)\n",
        "\n",
        "  #test_pred = (lgbm.predict(X_test) + xgb.predict(X_test)) / 2\n",
        "  #test_pred = np.where(test_pred < 0, 0, test_pred)\n",
        "  #test_predictions.append(test_pred)\n",
        "\n",
        "#test_predictions = np.mean(test_predictions, axis=0)\n",
        "\n",
        "print('MAE score: ', mae_score / CFG.folds)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 526
        },
        "id": "QT_YDGRnHupN",
        "outputId": "10333135-cd17-449c-c75c-1965d6b642df"
      },
      "execution_count": 18,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[LightGBM] [Warning] Auto-choosing row-wise multi-threading, the overhead of testing was 0.014599 seconds.\n",
            "You can set `force_row_wise=true` to remove the overhead.\n",
            "And if memory is not enough, you can set `force_col_wise=true`.\n",
            "[LightGBM] [Info] Total Bins 1689\n",
            "[LightGBM] [Info] Number of data points in the train set: 293931, number of used features: 16\n",
            "[LightGBM] [Info] Start training from score 61.745688\n",
            "Fold0 MAE:  43.20186665304422\n"
          ]
        },
        {
          "output_type": "error",
          "ename": "KeyboardInterrupt",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-18-78844fb2c33e>\u001b[0m in \u001b[0;36m<cell line: 10>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     12\u001b[0m   \u001b[0mX_valid\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my_valid\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtrain\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mloc\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mvalid_idx\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfeatures\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtrain\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mloc\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mvalid_idx\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtarget\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     13\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 14\u001b[0;31m   \u001b[0mxgb\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX_train\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my_train\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     15\u001b[0m   \u001b[0mlgbm\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX_train\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my_train\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     16\u001b[0m   \u001b[0;31m#xgb_pred = xgb.predict(X_valid)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/xgboost/core.py\u001b[0m in \u001b[0;36minner_f\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    727\u001b[0m             \u001b[0;32mfor\u001b[0m \u001b[0mk\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0marg\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mzip\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msig\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mparameters\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0margs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    728\u001b[0m                 \u001b[0mkwargs\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mk\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0marg\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 729\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mfunc\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    730\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    731\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0minner_f\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/xgboost/sklearn.py\u001b[0m in \u001b[0;36mfit\u001b[0;34m(self, X, y, sample_weight, base_margin, eval_set, eval_metric, early_stopping_rounds, verbose, xgb_model, sample_weight_eval_set, base_margin_eval_set, feature_weights, callbacks)\u001b[0m\n\u001b[1;32m   1084\u001b[0m                 \u001b[0mxgb_model\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0meval_metric\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mparams\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mearly_stopping_rounds\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcallbacks\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1085\u001b[0m             )\n\u001b[0;32m-> 1086\u001b[0;31m             self._Booster = train(\n\u001b[0m\u001b[1;32m   1087\u001b[0m                 \u001b[0mparams\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1088\u001b[0m                 \u001b[0mtrain_dmatrix\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/xgboost/core.py\u001b[0m in \u001b[0;36minner_f\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    727\u001b[0m             \u001b[0;32mfor\u001b[0m \u001b[0mk\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0marg\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mzip\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msig\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mparameters\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0margs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    728\u001b[0m                 \u001b[0mkwargs\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mk\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0marg\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 729\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mfunc\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    730\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    731\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0minner_f\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/xgboost/training.py\u001b[0m in \u001b[0;36mtrain\u001b[0;34m(params, dtrain, num_boost_round, evals, obj, feval, maximize, early_stopping_rounds, evals_result, verbose_eval, xgb_model, callbacks, custom_metric)\u001b[0m\n\u001b[1;32m    179\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mcb_container\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbefore_iteration\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mbst\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mi\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdtrain\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mevals\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    180\u001b[0m             \u001b[0;32mbreak\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 181\u001b[0;31m         \u001b[0mbst\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mupdate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdtrain\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mi\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mobj\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    182\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mcb_container\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mafter_iteration\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mbst\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mi\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdtrain\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mevals\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    183\u001b[0m             \u001b[0;32mbreak\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/xgboost/core.py\u001b[0m in \u001b[0;36mupdate\u001b[0;34m(self, dtrain, iteration, fobj)\u001b[0m\n\u001b[1;32m   2048\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mfobj\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2049\u001b[0m             _check_call(\n\u001b[0;32m-> 2050\u001b[0;31m                 _LIB.XGBoosterUpdateOneIter(\n\u001b[0m\u001b[1;32m   2051\u001b[0m                     \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mhandle\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mctypes\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mc_int\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0miteration\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdtrain\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mhandle\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2052\u001b[0m                 )\n",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "kf = KFold(n_splits=CFG.folds, shuffle=True, random_state=42)\n",
        "xgb = xgboost.XGBRegressor(n_estimators=100,max_depth=3,learning_rate=0.2,subsample=0.9,colsample_bytree=0.8)\n",
        "lgbm = lightgbm.LGBMRegressor()\n",
        "\n",
        "port_mae_score = []\n",
        "for port in train['ARI_PO'].unique():\n",
        "  print('='*10 + f'{port}' + '='*10)\n",
        "  train_ = train[train['ARI_PO'] == port].reset_index(drop=True)\n",
        "  mae_score = 0\n",
        "\n",
        "  for fold, (train_idx, valid_idx) in enumerate(kf.split(train_)):\n",
        "    X_train, y_train = train_.loc[train_idx, features], train_.loc[train_idx, target]\n",
        "    X_valid, y_valid = train_.loc[valid_idx, features], train_.loc[valid_idx, target]\n",
        "\n",
        "    xgb.fit(X_train, y_train)\n",
        "    pred = xgb.predict(X_valid)\n",
        "    #lgbm.fit(X_train, y_train)\n",
        "    #pred = lgbm.predict(X_valid)\n",
        "    pred = np.where(pred < 0, 0, pred)\n",
        "\n",
        "    print(f'Fold{fold} MAE: ', mean_absolute_error(y_valid, pred))\n",
        "    mae_score += mean_absolute_error(y_valid, pred)\n",
        "\n",
        "  print('MAE score: ', mae_score / CFG.folds)\n",
        "  port_mae_score.append(mae_score / CFG.folds)\n",
        "\n",
        "  print('='*30)\n",
        "\n",
        "print('Total MAE score: ', np.mean(port_mae_score))"
      ],
      "metadata": {
        "id": "yzv-ga_UKgz4"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#def build_model():\n",
        "    inp = tf.keras.Input(shape=(len(features), 1))\n",
        "\n",
        "    x = tf.keras.layers.GRU(units=8, return_sequences=True)(inp)\n",
        "    x = tf.keras.layers.GRU(units=8, return_sequences=True)(x)\n",
        "    x = tf.keras.layers.GRU(units=8, return_sequences=False)(x)\n",
        "    x = tf.keras.layers.Dense(1,activation='linear')(x)\n",
        "    model = tf.keras.Model(inputs=inp, outputs=x)\n",
        "\n",
        "    opt = tf.keras.optimizers.Adam(learning_rate=1e-5)\n",
        "    loss = tf.keras.losses.MeanAbsoluteError()\n",
        "    model.compile(loss=loss, optimizer = opt)\n",
        "\n",
        "    return model"
      ],
      "metadata": {
        "id": "pVKeVg-sAhg3"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "model = build_model()\n",
        "model.summary()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "qLr8AKwJAi9t",
        "outputId": "003c3bcd-8c27-44e2-9cff-e4e27249d7c8"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Model: \"model\"\n",
            "_________________________________________________________________\n",
            " Layer (type)                Output Shape              Param #   \n",
            "=================================================================\n",
            " input_1 (InputLayer)        [(None, 20, 1)]           0         \n",
            "                                                                 \n",
            " gru (GRU)                   (None, 20, 8)             264       \n",
            "                                                                 \n",
            " gru_1 (GRU)                 (None, 20, 8)             432       \n",
            "                                                                 \n",
            " gru_2 (GRU)                 (None, 8)                 432       \n",
            "                                                                 \n",
            " dense (Dense)               (None, 1)                 9         \n",
            "                                                                 \n",
            "=================================================================\n",
            "Total params: 1137 (4.44 KB)\n",
            "Trainable params: 1137 (4.44 KB)\n",
            "Non-trainable params: 0 (0.00 Byte)\n",
            "_________________________________________________________________\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "def build_model():\n",
        "    inp = tf.keras.Input(shape=(len(features,)))\n",
        "\n",
        "    x = tf.keras.layers.Dense(CFG.hidden_size,activation=CFG.activation)(inp)\n",
        "    for k in range(CFG.hidden_layers-1):\n",
        "        x = tf.keras.layers.Dense(CFG.hidden_size)(x)\n",
        "        x = tf.keras.layers.Activation(CFG.activation)(x)\n",
        "    x = tf.keras.layers.Dense(1,activation='linear')(x)\n",
        "\n",
        "    model = tf.keras.Model(inputs=[inp], outputs=[x])\n",
        "    opt = tf.keras.optimizers.Adam(learning_rate=1e-3)\n",
        "    loss = tf.keras.losses.MeanAbsoluteError()\n",
        "    model.compile(loss=loss, optimizer = opt)\n",
        "\n",
        "    return model"
      ],
      "metadata": {
        "id": "VpOFWyptSzmY"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "model = build_model()\n",
        "model.summary()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "PHDww2w-S1FD",
        "outputId": "010741e1-0165-4c5d-d3bd-2ac04aa6d04a"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Model: \"model\"\n",
            "_________________________________________________________________\n",
            " Layer (type)                Output Shape              Param #   \n",
            "=================================================================\n",
            " input_1 (InputLayer)        [(None, 23)]              0         \n",
            "                                                                 \n",
            " dense (Dense)               (None, 24)                576       \n",
            "                                                                 \n",
            " dense_1 (Dense)             (None, 24)                600       \n",
            "                                                                 \n",
            " activation (Activation)     (None, 24)                0         \n",
            "                                                                 \n",
            " dense_2 (Dense)             (None, 24)                600       \n",
            "                                                                 \n",
            " activation_1 (Activation)   (None, 24)                0         \n",
            "                                                                 \n",
            " dense_3 (Dense)             (None, 24)                600       \n",
            "                                                                 \n",
            " activation_2 (Activation)   (None, 24)                0         \n",
            "                                                                 \n",
            " dense_4 (Dense)             (None, 24)                600       \n",
            "                                                                 \n",
            " activation_3 (Activation)   (None, 24)                0         \n",
            "                                                                 \n",
            " dense_5 (Dense)             (None, 24)                600       \n",
            "                                                                 \n",
            " activation_4 (Activation)   (None, 24)                0         \n",
            "                                                                 \n",
            " dense_6 (Dense)             (None, 24)                600       \n",
            "                                                                 \n",
            " activation_5 (Activation)   (None, 24)                0         \n",
            "                                                                 \n",
            " dense_7 (Dense)             (None, 24)                600       \n",
            "                                                                 \n",
            " activation_6 (Activation)   (None, 24)                0         \n",
            "                                                                 \n",
            " dense_8 (Dense)             (None, 24)                600       \n",
            "                                                                 \n",
            " activation_7 (Activation)   (None, 24)                0         \n",
            "                                                                 \n",
            " dense_9 (Dense)             (None, 24)                600       \n",
            "                                                                 \n",
            " activation_8 (Activation)   (None, 24)                0         \n",
            "                                                                 \n",
            " dense_10 (Dense)            (None, 1)                 25        \n",
            "                                                                 \n",
            "=================================================================\n",
            "Total params: 6001 (23.44 KB)\n",
            "Trainable params: 6001 (23.44 KB)\n",
            "Non-trainable params: 0 (0.00 Byte)\n",
            "_________________________________________________________________\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "kf = KFold(n_splits=CFG.folds, shuffle=True, random_state=42)\n",
        "#gkf = GroupKFold(n_splits=CFG.folds)\n",
        "#xgb = xgboost.XGBRegressor()\n",
        "#gru = build_model()\n",
        "mlp = build_model()\n",
        "\n",
        "mae_score = 0\n",
        "for fold, (train_idx, valid_idx) in enumerate(kf.split(train)):\n",
        "  X_train, y_train = train.loc[train_idx, features], train.loc[train_idx, target]\n",
        "  X_valid, y_valid = train.loc[valid_idx, features], train.loc[valid_idx, target]\n",
        "\n",
        "  #xgb.fit(X_train, y_train)\n",
        "  #xgb_pred = xgb.predict(X_valid)\n",
        "\n",
        "  #gru.fit(X_train, y_train, validation_data = (X_valid, y_valid), batch_size = 16, epochs = 1)\n",
        "  #gru_pred = gru.predict(X_valid)\n",
        "\n",
        "  mlp.fit(X_train, y_train, validation_data = (X_valid, y_valid), verbose=2, batch_size = 32, epochs = 12)\n",
        "  mlp_pred = mlp.predict(X_valid)\n",
        "\n",
        "  pred = mlp_pred\n",
        "  pred = np.where(pred < 0, 0, pred)\n",
        "\n",
        "  print(f'Fold{fold} MAE: ', mean_absolute_error(y_valid, pred))\n",
        "\n",
        "  mae_score += mean_absolute_error(y_valid, pred)\n",
        "\n",
        "print('MAE score: ', mae_score / CFG.folds)"
      ],
      "metadata": {
        "id": "J3pKB3ioXEfq"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "8ZxO7XPp0vEk"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}